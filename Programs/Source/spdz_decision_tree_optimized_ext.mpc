# coding: latin-1
"""
  This is the spdz decision tree program.

  Preparations: currently need to setup the hyper-parameters before compilation, including,
        MAX_TREE_DEPTH: the maximum tree depth of the decision tree model
        TREE_NODE_NUM: the maximum tree nodes in the model, i.e., 2^(MAX_TREE_DEPTH + 1) - 1
        SAMPLE_NUM: the number of samples in the training dataset
        CLASS_NUM: the number of classes in the classification task; if regression, set to 1
        PRUNING_SAMPLE_NUM: the threshold number of samples required on any tree node
        MAX_SPLIT_NUM: the maximum number of splits for any feature
        MAX_NUM_CLIENTS: the total client number
        FEATURE_NUM_CLIENT_i: the number of features for client i
        FEATURE_NUM: the total feature number

  The main steps include:
  (1) keep waiting enough clients connected to this program. Once enough clients connected, read the training values as well as
  the split nums and split values;
  (2) iteratively training, for each available tree node:
        (a) judge whether some pruning conditions are satisfied
            (a.1) feature_iv.sum == 0
            (a.2) sample_iv.sum <= SAMPLE_NUM_PRUNING
            (a.3) samples belong to the same class
        (b) if satisfied:
            (b.1) find the majority class
        (c) else not satisfied
            (c.1) for each available feature:
            (c.2)   for each available split:
            (c.3)      for each class:
            (c.4)         compute the class count for both left branch and right branch
            (c.5)      compute impurity for the current split
            (c.6)      if current impurity < best impurity: update the records
        (d) record the best feature id and best split id, and update sample_iv as well as feature_iv
  (3) return the final tree models

"""

from Compiler.types import sint, regint, Array, MemValue
from Compiler.instructions import listen, acceptclientconnection
from Compiler.library import print_ln, do_while, for_range
from Compiler.util import if_else
from Compiler import mpc_math, floatingpoint
from random import seed, randrange
from Compiler.program import Program
import ml


FIXED_F = 8
FIXED_K = 31
sfix.set_precision(FIXED_F, FIXED_K)
cfix.set_precision(FIXED_F, FIXED_K)

MAX_TREE_DEPTH = 3
TREE_NODE_NUM = 15 #2^(MAX_TREE_DEPTH + 1) - 1
SAMPLE_NUM = 3616
CLASS_NUM = 2
PRUNING_SAMPLE_NUM = 5
MAX_SPLIT_NUM = 8
FEATURE_NUM_CLIENT_1 = 6
FEATURE_NUM_CLIENT_2 = 5
FEATURE_NUM_CLIENT_3 = 5
FEATURE_NUM = 16
PORT_NUM = 20000
MAX_NUM_CLIENTS = 3
OVERFLOW_THRESHOLD = 0.0001

feature_nums = Array(MAX_NUM_CLIENTS, cint)
feature_nums[0] = FEATURE_NUM_CLIENT_1
feature_nums[1] = FEATURE_NUM_CLIENT_2
feature_nums[2] = FEATURE_NUM_CLIENT_3

training_data = sfix.Matrix(SAMPLE_NUM, FEATURE_NUM)     # read from clients
training_labels = Array(SAMPLE_NUM, sfix)                # read from client 0
split_nums = Array(FEATURE_NUM, sfix)                    # read from clients
split_values = sfix.Matrix(FEATURE_NUM, MAX_SPLIT_NUM)   # read from clients
feature_left_split_ivs = MultiArray([FEATURE_NUM, MAX_SPLIT_NUM, SAMPLE_NUM], sint)  #read from clients
feature_right_split_ivs = MultiArray([FEATURE_NUM, MAX_SPLIT_NUM, SAMPLE_NUM], sint) #read from clients
class_ivs = sint.Matrix(CLASS_NUM, SAMPLE_NUM)           # read from client 0

tree_nodes = Array(TREE_NODE_NUM, cint)                  # updated during training
sample_ivs = sint.Matrix(TREE_NODE_NUM, SAMPLE_NUM)      # updated during training
feature_ivs = cint.Matrix(TREE_NODE_NUM, FEATURE_NUM)    # updated during training
is_satisfied = Array(1, cint)


# accept a client's connection
def accept_client():
    client_socket_id = regint()
    acceptclientconnection(client_socket_id, PORT_NUM)
    return client_socket_id


# receive clients split_num and split_values
def client_split_parameters(client_socket_id):

    start_index = Array(1, cint)
    start_index[0] = 0

    @if_e(client_socket_id == 0)
    def _():
        start_index[0] = 0
    @else_
    def _():
        @for_range(MAX_NUM_CLIENTS)
        def _(i):
            @if_(i < client_socket_id)
            def _():
                start_index[0] = start_index[0] + feature_nums[i]
                #print_ln('i = %s, start_index[0] = %s', i, start_index[0])

    print_ln('client_socket_id = %s, start_index[0] = %s', client_socket_id, start_index[0])

    @for_range(feature_nums[client_socket_id])
    def _(i):
        @for_range(MAX_SPLIT_NUM + 1)
        def _(j):
            tmp_array = Array.create_from(sint.receive_from_client(1, client_socket_id))
            #print_ln('tmp_array[0] = %s', tmp_array[0].reveal())
            @if_e(j == 0)
            def _():
                split_nums[start_index[0] + i] = sfix._new(tmp_array[0])
                #print_ln('split_nums[%s] = %s', start_index[0] + i, split_nums[start_index[0] + i].reveal())
            @else_
            def _():
                split_values[start_index[0] + i][j] = sfix._new(tmp_array[0])
                #print_ln('split_values[%s][%s] = %s', start_index[0] + i, j, split_values[start_index[0] + i][j].reveal())

    print_ln('Read split parameters from client %s finished', client_socket_id)
    return True


# receive client 0's labels
def client_training_labels_input(client_socket_id):
    tmp_array = Array(1, sint)
    @for_range(SAMPLE_NUM)
    def _(i):
        tmp_array = sint.receive_from_client(1, client_socket_id)
        training_labels[i] = sfix._new(tmp_array[0])
        #print_ln('training_labels[%s] = %s', i, training_labels[i].reveal())

    print_ln('Read training labels from client %s finished', client_socket_id)
    return True

# receive client 0's class ivs
def client_class_ivs(client_socket_id):
    tmp_array = Array(1, sint)
    @for_range(CLASS_NUM)
    def _(i):
        @for_range(SAMPLE_NUM)
        def _(j):
            tmp_array = sint.receive_from_client(1, client_socket_id)
            class_ivs[i][j] = tmp_array[0]

    print_ln('Read class ivs from client %s finished', client_socket_id)
    return True


# receive client's feature split ivs
def client_feature_split_ivs(client_socket_id):

    start_index = Array(1, cint)
    start_index[0] = 0

    @if_e(client_socket_id == 0)
    def _():
        start_index[0] = 0
    @else_
    def _():
        @for_range(MAX_NUM_CLIENTS)
        def _(i):
            @if_(i < client_socket_id)
            def _():
                start_index[0] = start_index[0] + feature_nums[i]

    tmp_array = Array(1, sint)
    @for_range(feature_nums[client_socket_id])
    def _(i):
        @for_range(MAX_SPLIT_NUM)
        def _(s):
            @for_range(SAMPLE_NUM)
            def _(j):
                tmp_array = sint.receive_from_client(1, client_socket_id)
                #print_ln('tmp_array[0] = %s', tmp_array[0].reveal())
                feature_left_split_ivs[start_index[0] + i][s][j] = tmp_array[0]

        @for_range(MAX_SPLIT_NUM)
        def _(s):
            @for_range(SAMPLE_NUM)
            def _(j):
                tmp_array = sint.receive_from_client(1, client_socket_id)
                feature_right_split_ivs[start_index[0] + i][s][j] = tmp_array[0]

    print_ln('Read feature split_ivs from client %s', client_socket_id)
    return True

# receive a client's private training data
def client_training_data_input(client_socket_id):

    start_index = Array(1, cint)
    start_index[0] = 0

    @if_e(client_socket_id == 0)
    def _():
        start_index[0] = 0
    @else_
    def _():
        @for_range(MAX_NUM_CLIENTS)
        def _(i):
            @if_(i < client_socket_id)
            def _():
                start_index[0] = start_index[0] + feature_nums[i]

    tmp_array = Array(1, sint)
    @for_range(SAMPLE_NUM)
    def _(i):
        @for_range(feature_nums[client_socket_id])
        def _(j):
            tmp_array = sint.receive_from_client(1, client_socket_id)
            training_data[i][start_index[0] + j] = sfix._new(tmp_array[0])

    print_ln('Read data from client %s finished', client_socket_id)
    return True


# check pruning conditions
def check_pruning_conditions(node_index):

    print_ln('node_index = %s', node_index)
    is_satisfied[0] = 0

    # check node depth
    @if_e(2 * node_index + 2 > TREE_NODE_NUM)
    def _():
        is_satisfied[0] = 1
    @else_
    def _():
        # check the 1st condition
        feature_sum = Array(1, cint)
        feature_sum[0] = 0

        @for_range(FEATURE_NUM)
        def _(i):
            feature_sum[0] = feature_sum[0] + feature_ivs[node_index][i]

        print_ln('feature_sum[0] = %s', feature_sum[0])
        @if_e(feature_sum[0] == 0)
        def _():
            is_satisfied[0] = 1
        @else_
        def _():
            # check the 2nd condition
            sample_sum = Array(1, sint)
            sample_sum[0] = 0

            @for_range(SAMPLE_NUM)
            def _(i):
                sample_sum[0] = sample_sum[0] + sample_ivs[node_index][i]

            print_ln('sample_sum[0] = %s', sample_sum[0].reveal())
            @if_e(sample_sum[0].reveal() == 0)
            def _():
                is_satisfied[0] = 1
            @else_
            def _():
                # check the 3rd condition
                class_sums = Array(CLASS_NUM, sint)
                @for_range(CLASS_NUM)
                def _(i):
                    class_sums[i] = 0

                non_zero_count = Array(1, cint)
                non_zero_count[0] = 0

                @for_range(CLASS_NUM)
                def _(i):
                    @for_range(SAMPLE_NUM)
                    def _(j):
                        @if_(sample_ivs[node_index][j].reveal() == 1 and training_labels[j].reveal() == i)
                        def _():
                            class_sums[i] = class_sums[i] + 1

                    @if_(class_sums[i].reveal() != 0)
                    def _():
                        non_zero_count[0] = non_zero_count[0] + 1

                print_ln('non_zero_count[0] = %s', non_zero_count[0].reveal())

                @if_(non_zero_count[0] == 1)
                def _():
                    is_satisfied[0] = 1

    return True


# build the tree nodes
def build_tree():

    # init tree nodes
    @for_range(TREE_NODE_NUM)
    def _(i):
        tree_nodes[i] = -1
    tree_nodes[0] = 1

    @for_range(FEATURE_NUM)
    def _(i):
        feature_ivs[0][i] = 1

    @for_range(SAMPLE_NUM)
    def _(i):
        sample_ivs[0][i] = 1

    internal_node_num = Array(1, cint)
    internal_node_num[0] = 0

    @for_range(TREE_NODE_NUM)
    def _(i):
        print_ln('begin to build tree node %s', i);
        print_ln('tree_nodes[%s] = %s', i, tree_nodes[i])

        # check if the current node is available
        @if_(tree_nodes[i] != -1)
        def _():
            check_pruning_conditions(i)
            print_ln('is_satisfied[0] = %s', is_satisfied[0])
            @if_e(is_satisfied[0] == 1)
            def _():
                print_ln('Pruning condition satisfied')
                # find majority class
                print_ln('The current tree node is a leaf')
            @else_
            def _():
                print_ln('Pruning condition not satisfied')

                # find the best split
                best_impurity = Array(1, sfix)
                best_impurity[0] = 1000.0
                best_feature_id = Array(1, cint)
                best_feature_id[0] = -1
                best_split_value = Array(1, cint)
                best_split_value[0] = -1

                @for_range(FEATURE_NUM)
                def _(j):
                    print_ln('feature_ivs[%s][%s] = %s', i, j, feature_ivs[i][j])
                    @if_(feature_ivs[i][j] == 1)
                    def _():
                        @for_range(MAX_SPLIT_NUM)
                        def _(s):
                            #print_ln('****** s = %s, split_nums[%s] = %s', s, j, split_nums[j].reveal())
                            @if_((s < split_nums[j]).reveal() == 1)
                            def _():
                                #print_ln('Begin compute impurities')
                                left_impurity = Array(1, sfix)
                                left_impurity[0] = 1.0
                                right_impurity = Array(1, sfix)
                                right_impurity[0] = 1.0

                                left_sum = Array(1, sfix)
                                left_sum[0] = 0
                                right_sum = Array(1, sfix)
                                right_sum[0] = 0
                                left_probs = Array(CLASS_NUM, sfix)
                                right_probs = Array(CLASS_NUM, sfix)
                                @for_range(CLASS_NUM)
                                def _(c):
                                    left_probs[c] = 0
                                    right_probs[c] = 0

                                #cur_split_value = split_values[j][s]

                                left_split_iv_array = feature_left_split_ivs[j][s]
                                right_split_iv_array = feature_right_split_ivs[j][s]

                                test_sample_num = Array(1, sfix)
                                test_split_iv_sum = Array(1, sfix)
                                test_sample_num[0] = 0
                                test_split_iv_sum[0] = 0

                                @for_range(SAMPLE_NUM)
                                def _(k):
                                    left_sum[0] = left_sum[0] + sample_ivs[i][k] * left_split_iv_array[k]
                                    right_sum[0] = right_sum[0] + sample_ivs[i][k] * right_split_iv_array[k]
                                    test_sample_num[0] = test_sample_num[0] + sample_ivs[i][k]
                                    test_split_iv_sum[0] = test_split_iv_sum[0] + left_split_iv_array[k]
                                    test_split_iv_sum[0] = test_split_iv_sum[0] + right_split_iv_array[k]

                                """
                                @for_range(SAMPLE_NUM)
                                def _(k):
                                    @if_(sample_ivs[i][k].reveal() == 1)
                                    def _():
                                        @if_e(left_split_iv_array[k].reveal() == 1)
                                        def _():
                                            left_sum[0] = left_sum[0] + 1
                                        @else_
                                        def _():
                                            right_sum[0] = right_sum[0] + 1
                                """

                                @for_range(CLASS_NUM)
                                def _(c):
                                    @for_range(SAMPLE_NUM)
                                    def _(k):
                                        left_probs[c] = left_probs[c] + sample_ivs[i][k] * left_split_iv_array[k] * class_ivs[c][k]
                                        right_probs[c] = right_probs[c] + sample_ivs[i][k] * right_split_iv_array[k] * class_ivs[c][k]

                                """
                                @for_range(CLASS_NUM)
                                def _(c):
                                    @for_range(SAMPLE_NUM)
                                    def _(k):
                                        @if_(sample_ivs[i][k].reveal() == 1)
                                        def _():
                                            @if_e(left_split_iv_array[k].reveal() == 1)
                                            def _():
                                                @if_((training_labels[k] == (c+1)).reveal() == 1)
                                                def _():
                                                    left_probs[c] = left_probs[c] + 1
                                            @else_
                                            def _():
                                                @if_((training_labels[k] == (c+1)).reveal() == 1)
                                                def _():
                                                    right_probs[c] = right_probs[c] + 1
                                """

                                #print_ln('****** left_sum[0] = %s', left_sum[0].reveal())
                                #print_ln('****** right_sum[0] = %s', right_sum[0].reveal())
                                #print_ln('****** test_sample_num[0] = %s', test_sample_num[0].reveal())
                                #print_ln('****** test_split_iv_sum[0] = %s', test_split_iv_sum[0].reveal())

                                @for_range(CLASS_NUM)
                                def _(c):
                                    left_probs[c] = left_probs[c] / left_sum[0]
                                    #print_ln('****** left_probs[%s] = %s', c, left_probs[c].reveal())
                                    left_impurity[0] = left_impurity[0] - (left_probs[c] * left_probs[c])
                                    right_probs[c] = right_probs[c] / right_sum[0]
                                    #print_ln('****** right_probs[%s] = %s', c, right_probs[c].reveal())
                                    right_impurity[0] = right_impurity[0] - (right_probs[c] * right_probs[c])

                                # weighted impurity computation
                                left_impurity[0] = (left_impurity[0] * left_sum[0]) / (left_sum[0] + right_sum[0])
                                right_impurity[0] = (right_impurity[0] * right_sum[0]) / (left_sum[0] + right_sum[0])

                                #print_ln('****** left_impurity[0] = %s', left_impurity[0].reveal())
                                #print_ln('****** right_impurity[0] = %s', right_impurity[0].reveal())

                                @if_((best_impurity[0] > (left_impurity[0] + right_impurity[0])).reveal())
                                def _():
                                    best_impurity[0] = left_impurity[0] + right_impurity[0]
                                    best_feature_id[0] = j
                                    best_split_value[0] = s

                print_ln('The best_feature_id = %s', best_feature_id[0])
                print_ln('The best_impurity = %s', best_impurity[0].reveal())

                @if_(mpc_math.abs_fx(best_impurity[0]).reveal() < OVERFLOW_THRESHOLD)
                def _():
                    best_impurity[0] = 0

                @if_((2 * i + 1) < TREE_NODE_NUM and (best_impurity[0].reveal() != 0))
                def _():
                    internal_node_num[0] = internal_node_num[0] + 1
                    print_ln('The internal node num = %s', internal_node_num[0])
                    tree_nodes[2 * i + 1] = 1
                    tree_nodes[2 * i + 2] = 1

                    # update the sample_ivs and feature_ivs of the two child nodes
                    @for_range(FEATURE_NUM)
                    def _(t):
                        @if_e(t == best_feature_id[0])
                        def _():
                            feature_ivs[2 * i + 1][t] = 0
                            feature_ivs[2 * i + 2][t] = 0
                        @else_
                        def _():
                            feature_ivs[2 * i + 1][t] = feature_ivs[i][t]
                            feature_ivs[2 * i + 2][t] = feature_ivs[i][t]

                    left_split_iv_array = feature_left_split_ivs[best_feature_id[0]][best_split_value[0]]
                    right_split_iv_array = feature_right_split_ivs[best_feature_id[0]][best_split_value[0]]

                    @for_range(SAMPLE_NUM)
                    def _(t):
                        sample_ivs[2 * i + 1][t] = sample_ivs[i][t] * left_split_iv_array[t]
                        sample_ivs[2 * i + 2][t] = sample_ivs[i][t] * right_split_iv_array[t]
                        """
                        @if_e(left_split_iv_array[t].reveal() == 1)
                        def _():
                            sample_ivs[2 * i + 1][t] = sample_ivs[i][t] * 1
                            sample_ivs[2 * i + 2][t] = sample_ivs[i][t] * 0
                        @else_
                        def _():
                            sample_ivs[2 * i + 1][t] = sample_ivs[i][t] * 0
                            sample_ivs[2 * i + 2][t] = sample_ivs[i][t] * 1
                        """
        print_ln('End to build tree node %s', i);

    print_ln('The internal node num = %s', internal_node_num[0])
    return True


# write result to all the clients, where best_split_index is public while best_left_impurity and best_right_impurity are private
def write_result_to_clients(sockets, number_clients, finished):

    # Send share of result to all clients. However, in this way, every client receives the final result, which is not desirable,
    # should split the result array into number_clients shares, and send each share to each client

    #print_ln('begin to write best_split_index to each client')
    @for_range(number_clients)
    def loop_body(i):
        #print_ln('socket[%s] = %s', i, sockets[i])
        cint.write_to_socket(sockets[i], finished)


def main():
    """Listen for clients to join a game.
    Once maximum reached or have notified that round finished, run comparison and return result."""
    # Start listening for client socket connections
    listen(PORT_NUM)
    print_ln('Listening for client connections on base port %s', PORT_NUM)

    @do_while
    def computing_loop():

        print_ln('Starting a new recursive node.')

        # Clients socket id (integer).
        client_sockets = Array(MAX_NUM_CLIENTS, regint)
        # Number of clients
        number_clients = MemValue(regint(0))
        # Keep track of received inputs
        seen = Array(MAX_NUM_CLIENTS, regint)
        seen.assign_all(0)

        # step 1: Loop round waiting for each client to connect
        @do_while
        def client_connections():
            client_id = accept_client()
            @if_(client_id >= MAX_NUM_CLIENTS)
            def _():
                print_ln('client id too high')
                crash()
            client_sockets[client_id] = client_id
            seen[client_id] = 1
            return sum(seen) < MAX_NUM_CLIENTS

        print_ln('Finish step 1')

        # step 2: Receive training data from the clients
        @for_range(MAX_NUM_CLIENTS)
        def _(client_id):
            client_training_data_input(client_id)

        #@for_range(SAMPLE_NUM)
        #def _(i):
        #    @for_range(FEATURE_NUM)
        #    def _(j):
        #        print_ln('training_data[%s][%s] = %s', i, j, training_data[i][j].reveal())

        print_ln('Finish step 2')

        # step 3: Receive training labels form client 0
        client_training_labels_input(client_sockets[0])
        client_class_ivs(client_sockets[0])

        print_ln('Finish step 3')

        # step 4: Receive split parameters from the clients
        @for_range(MAX_NUM_CLIENTS)
        def _(client_id):
            client_split_parameters(client_id)
            client_feature_split_ivs(client_id)

        #@for_range(FEATURE_NUM)
        #def _(i):
        #    print_ln('split_nums[%s] = %s', i, split_nums[i].reveal())
        #    @for_range(MAX_SPLIT_NUM + 1)
        #    def _(j):
        #        print_ln('split_values[%s][%s] = %s', i, j, split_values[i][j].reveal())

        print_ln('Finish step 4')

        # step 5: Build tree
        build_tree()

        print_ln('Finish step 5')

        finished = Array(1, cint)
        finished[0] = 1
        write_result_to_clients(client_sockets, MAX_NUM_CLIENTS, finished[0])

        # truncate the overflow values around 0
        #@for_range(global_split_num)
        #def _(i):
        #    @for_range(classes_num * 2)
        #    def _(j):
        #        @if_(mpc_math.abs_fx(clients_statistics[i][j]).reveal() < OVERFLOW_THRESHOLD)
        #        def _():
        #            clients_statistics[i][j] = 0

        return True

main()